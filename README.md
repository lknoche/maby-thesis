# MABY-Thesis: Yeast Compartment Segmentation with U-Net and Classical Methods

This repository contains the codebase used for my bachelor thesis project:  
**"Deep Learning vs Classical Segmentation: A Study on Yeast Cell Compartments"**

It extends [adjavon/maby](https://github.com/adjavon/maby) with a full training and evaluation pipeline for U-Net segmentation and comparisons with classical methods like Cellpose and Otsu thresholding.

ðŸ”— Repository: [https://github.com/lknoche/maby-thesis](https://github.com/lknoche/maby-thesis)

---

## Project Structure:
maby-thesis/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ train.py                      # Train U-Net on tile-based images
â”œâ”€â”€ test.py                       # Evaluate trained model with F1 and similarity
â”œâ”€â”€ dataset.py                    # Dataset loading and augmentation
â”œâ”€â”€ image.py                      # Image handling and preprocessing
â”œâ”€â”€ download_and_run.py           # Downloads from OMERO and runs training
â”œâ”€â”€ alibylite.org                 # Optional config for OMERO/local paths

â”œâ”€â”€ export/
â”‚   â”œâ”€â”€ export_fluorescence_tiles.py
â”‚   â”œâ”€â”€ export_ground_truth_masks.py
â”‚   â”œâ”€â”€ export_gt_fluorescence_images.py
â”‚   â”œâ”€â”€ export_unet_tile_masks.py

â”œâ”€â”€ extract/
â”‚   â”œâ”€â”€ extract_bf_unetlike.py
â”‚   â”œâ”€â”€ extract_fluo.py
â”‚   â”œâ”€â”€ extract_selected_fluorescence_images.py
â”‚   â”œâ”€â”€ extract_unet_like_tiles.py
â”‚   â”œâ”€â”€ extract_unet_like_tiles_vacuole.py
â”‚   â”œâ”€â”€ extract_z_slices_for_qpi.py

â”œâ”€â”€ overlays/
â”‚   â”œâ”€â”€ make_combined_overlay_grid_vacuole.py
â”‚   â”œâ”€â”€ overlay_cellpose_vph1.py
â”‚   â”œâ”€â”€ run_cellpose_vph1.py
â”‚   â”œâ”€â”€ general_segmentation_otsu.py

â”œâ”€â”€ plots/
â”‚   â””â”€â”€ plot_results.py



##How to use:
1.Set up environment:
git clone https://github.com/lknoche/maby-thesis.git
cd maby-thesis
pip install -r requirements.txt
2. Preprocess Data:
If working with OMERO:
Use download_and_run.py to download and train:
python download_and_run.py -g Htb2_sfGFP
otherwise run train.py directly with the right directory:
python train.py -b /path/to/data -g Vph1_GFP
3. Evaluation:
python test.py  -g Vph1_GFP -m model_19.pt
4. Visualize Results:
python plots/plot_results.py

